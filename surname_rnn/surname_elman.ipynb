{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Data-Loading\" data-toc-modified-id=\"Data-Loading-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Loading</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Column-Gather-Understanding\" data-toc-modified-id=\"Column-Gather-Understanding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Column Gather Understanding</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surname Classifier Using ElmanRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:20:59.537930Z",
     "start_time": "2019-03-31T16:20:59.526922Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:00.119659Z",
     "start_time": "2019-03-31T16:20:59.539236Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:36.038840Z",
     "start_time": "2019-03-31T16:21:36.013206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('../data/surnames'),\n",
       " 'workdir': PosixPath('../data/surnames/rnn_workdir'),\n",
       " 'proc_dataset_csv': PosixPath('../data/surnames/surnames_with_splits.csv'),\n",
       " 'model_dir': PosixPath('../data/surnames/rnn_workdir/models'),\n",
       " 'vectorizer_json': PosixPath('../data/surnames/rnn_workdir/vectorizer.json'),\n",
       " 'metrics_file': PosixPath('../data/surnames/rnn_workdir/metrics.csv'),\n",
       " 'class_weights_pth': PosixPath('../data/surnames/rnn_workdir/class_weights.pth'),\n",
       " 'char_embedding_sz': 100,\n",
       " 'rnn_hidden_sz': 64,\n",
       " 'bs': 64,\n",
       " 'lr': 0.001,\n",
       " 'n_epochs': 97,\n",
       " 'device': 'cuda:3',\n",
       " 'checkpointer_prefix': 'surname_elman',\n",
       " 'checkpointer_name': 'classifier',\n",
       " 'es_patienct': 11,\n",
       " 'save_every': 2,\n",
       " 'save_total': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surname.dataset import SurnameDataset\n",
    "from surname.containers import DataContainer, ModelContainer\n",
    "from surname.model import SurnameClassifier\n",
    "from consts import consts\n",
    "vars(consts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:03.967121Z",
     "start_time": "2019-03-31T16:21:03.935162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>nationality_index</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nationality  nationality_index  split   surname\n",
       "0      Arabic                 15  train     Totah\n",
       "1      Arabic                 15  train    Abboud\n",
       "2      Arabic                 15  train  Fakhoury\n",
       "3      Arabic                 15  train     Srour\n",
       "4      Arabic                 15  train    Sayegh"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(consts.proc_dataset_csv)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:03.987524Z",
     "start_time": "2019-03-31T16:21:03.968303Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = DataContainer(df, SurnameDataset, consts.vectorizer_json, consts.bs, is_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:04.003538Z",
     "start_time": "2019-03-31T16:21:03.988435Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  class_weights = torch.load(consts.class_weights_pth)\n",
    "except FileNotFoundError:\n",
    "  nationality_vocab = dc.nationality_vocab\n",
    "  class_counts = df['nationality'].value_counts().to_dict()\n",
    "  sorted_counts = sorted(class_counts.items(), key=lambda x: nationality_vocab.lookup_token(x[0]))\n",
    "  freq = [count for _, count in sorted_counts]\n",
    "  class_weights = 1.0/torch.tensor(freq, dtype=torch.float32)\n",
    "  torch.save(class_weights, consts.class_weights_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:21:56.296562Z",
     "start_time": "2019-03-31T16:21:56.177131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurnameClassifier(\n",
       "  (emb): Embedding(80, 100, padding_idx=0)\n",
       "  (rnn): ElmanRNN(\n",
       "    (rnn_cell): RNNCell(100, 64)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=64, out_features=18, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SurnameClassifier(consts.char_embedding_sz, dc.vocab_size, dc.n_classes, consts.rnn_hidden_sz, \\\n",
    "                       padding_idx=dc.surname_vocab.mask_idx)\n",
    "loss_fn = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=consts.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.5, patience=1)\n",
    "mc = ModelContainer(classifier, optimizer, loss_fn, scheduler)\n",
    "mc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:22:07.821084Z",
     "start_time": "2019-03-31T16:22:07.805335Z"
    }
   },
   "outputs": [],
   "source": [
    "itr = iter(dc.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:22:07.854395Z",
     "start_time": "2019-03-31T16:22:07.822360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9217, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,l,y = next(itr)\n",
    "y_pred = mc.model(x,l)\n",
    "loss_fn(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Gather Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.303863Z",
     "start_time": "2019-03-31T14:58:49.234525Z"
    }
   },
   "outputs": [],
   "source": [
    "bs=3\n",
    "hidden_sz=7\n",
    "seq_sz =5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.318921Z",
     "start_time": "2019-03-31T14:58:49.305208Z"
    }
   },
   "outputs": [],
   "source": [
    "x_lens = torch.randint(1, seq_sz+1, (bs,))\n",
    "x_lens = x_lens.long().detach().cpu().numpy()-1\n",
    "y_out = torch.randn(bs, seq_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.333806Z",
     "start_time": "2019-03-31T14:58:49.320222Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_lens.shape)\n",
    "x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.349130Z",
     "start_time": "2019-03-31T14:58:49.335043Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_out.shape)\n",
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.362427Z",
     "start_time": "2019-03-31T14:58:49.350084Z"
    }
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for batch_idx, column_idx in enumerate(x_lens):\n",
    "  out.append(y_out[batch_idx, column_idx])\n",
    "#   print(batch_idx, column_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.375812Z",
     "start_time": "2019-03-31T14:58:49.363497Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.390314Z",
     "start_time": "2019-03-31T14:58:49.376865Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:16:21.508199Z",
     "start_time": "2019-03-31T16:16:21.492315Z"
    }
   },
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "  \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "  def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "               rnn_hidden_size, batch_first=True, padding_idx=0):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          embedding_size (int): The size of the character embeddings\n",
    "          num_embeddings (int): The number of characters to embed\n",
    "          num_classes (int): The size of the prediction vector \n",
    "              Note: the number of nationalities\n",
    "          rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "          batch_first (bool): Informs whether the input tensors will \n",
    "              have batch or the sequence on the 0th dimension\n",
    "          padding_idx (int): The index for the tensor padding; \n",
    "              see torch.nn.Embedding\n",
    "      \"\"\"\n",
    "      super(SurnameClassifier, self).__init__()\n",
    "\n",
    "      self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                              embedding_dim=embedding_size,\n",
    "                              padding_idx=padding_idx)\n",
    "      self.rnn = ElmanRNN(embedding_size,rnn_hidden_size,batch_first)\n",
    "      self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                       out_features=rnn_hidden_size)\n",
    "      self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                        out_features=num_classes)\n",
    "\n",
    "  def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "      \"\"\"The forward pass of the classifier\n",
    "\n",
    "      Args:\n",
    "          x_in (torch.Tensor): an input data tensor. \n",
    "              x_in.shape should be (batch, input_dim)\n",
    "          x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "              They are used to find the final vector of each sequence\n",
    "          apply_softmax (bool): a flag for the softmax activation\n",
    "              should be false if used with the Cross Entropy losses\n",
    "      Returns:\n",
    "          the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "      \"\"\"\n",
    "      x_embedded = self.emb(x_in)\n",
    "      y_out = self.rnn(x_embedded)\n",
    "\n",
    "      if x_lengths is not None:\n",
    "          y_out = column_gather(y_out, x_lengths)\n",
    "      else:\n",
    "          y_out = y_out[:, -1, :]\n",
    "\n",
    "      y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
    "      y_out = self.fc2(F.dropout(y_out, 0.5))\n",
    "\n",
    "      if apply_softmax:\n",
    "          y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "      return y_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
