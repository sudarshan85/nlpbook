{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Data-Loading\" data-toc-modified-id=\"Data-Loading-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Loading</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Column-Gather-Understanding\" data-toc-modified-id=\"Column-Gather-Understanding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Column Gather Understanding</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surname Classifier Using ElmanRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.017239Z",
     "start_time": "2019-03-31T16:17:00.006191Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.599999Z",
     "start_time": "2019-03-31T16:17:00.018333Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.664825Z",
     "start_time": "2019-03-31T16:17:00.601622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('../data/surnames'),\n",
       " 'workdir': PosixPath('../data/surnames/rnn_workdir'),\n",
       " 'proc_dataset_csv': PosixPath('../data/surnames/surnames_with_splits.csv'),\n",
       " 'model_dir': PosixPath('../data/surnames/rnn_workdir/models'),\n",
       " 'vectorizer_json': PosixPath('../data/surnames/rnn_workdir/vectorizer.json'),\n",
       " 'metrics_file': PosixPath('../data/surnames/rnn_workdir/metrics.csv'),\n",
       " 'class_weights_pth': PosixPath('../data/surnames/rnn_workdir/class_weights.pth'),\n",
       " 'char_embedding_sz': 100,\n",
       " 'rnn_hidden_sz': 64,\n",
       " 'bs': 64,\n",
       " 'lr': 0.001,\n",
       " 'n_epochs': 97,\n",
       " 'device': 'cuda:3',\n",
       " 'checkpointer_prefix': 'surname_elman',\n",
       " 'checkpointer_name': 'classifier',\n",
       " 'es_patienct': 11,\n",
       " 'save_every': 2,\n",
       " 'save_total': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surname.dataset import SurnameDataset\n",
    "from surname.containers import DataContainer\n",
    "from surname.elman import ElmanRNN\n",
    "from consts import consts\n",
    "vars(consts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.696027Z",
     "start_time": "2019-03-31T16:17:00.666482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>nationality_index</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nationality  nationality_index  split   surname\n",
       "0      Arabic                 15  train     Totah\n",
       "1      Arabic                 15  train    Abboud\n",
       "2      Arabic                 15  train  Fakhoury\n",
       "3      Arabic                 15  train     Srour\n",
       "4      Arabic                 15  train    Sayegh"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(consts.proc_dataset_csv)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.715836Z",
     "start_time": "2019-03-31T16:17:00.697306Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = DataContainer(df, SurnameDataset, consts.vectorizer_json, consts.bs, is_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.731638Z",
     "start_time": "2019-03-31T16:17:00.717070Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  class_weights = torch.load(consts.class_weights_pth)\n",
    "except FileNotFoundError:\n",
    "  nationality_vocab = dc.nationality_vocab\n",
    "  class_counts = df['nationality'].value_counts().to_dict()\n",
    "  sorted_counts = sorted(class_counts.items(), key=lambda x: nationality_vocab.lookup_token(x[0]))\n",
    "  freq = [count for _, count in sorted_counts]\n",
    "  class_weights = 1.0/torch.tensor(freq, dtype=torch.float32)\n",
    "  torch.save(class_weights, consts.class_weights_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.746464Z",
     "start_time": "2019-03-31T16:17:00.732688Z"
    }
   },
   "outputs": [],
   "source": [
    "def column_gather(y_out: torch.FloatTensor, x_lens: torch.FloatTensor) -> torch.FloatTensor:\n",
    "  \"\"\"\n",
    "    Get a specific vector from each batch datapoint in 'y_out'\n",
    "    Iteratove over batch row indices, get the vector thats at the position\n",
    "    indicated by the corresponding value in 'x_lens' at the row index\n",
    "    \n",
    "    Args:\n",
    "      y_out: shape (bs, seq_sz, feat_sz)\n",
    "      x_lens: shape (bs,)\n",
    "      \n",
    "    Returns:\n",
    "      y_out: shape (bs, feat_sz)\n",
    "  \"\"\"\n",
    "  x_lens = x_lens.long().detach().cpu().numpy()-1\n",
    "  \n",
    "  out = []\n",
    "  for batch_idx, column_idx in enumerate(x_lens):\n",
    "    out.append(y_out[batch_idx, column_idx])\n",
    "  \n",
    "  return torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:00.764057Z",
     "start_time": "2019-03-31T16:17:00.747589Z"
    }
   },
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "  \"\"\"\n",
    "    A Classifier with a RNN to extract features and an MLP to classify\n",
    "  \"\"\"\n",
    "  def __init__(self, emb_sz: int, n_embs: int, n_classes: int, rnn_hidden_sz:int ,\n",
    "               batch_first: bool=True, padding_idx: int=0) -> None:\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        emb_sz: the size of the character embeddings\n",
    "        n_embs: the number of characters to embed (vocabulary size)\n",
    "        n_classes: the size of the prediction vector\n",
    "        rnn_hidden_sz: the size of RNN's hidden state\n",
    "        batch_first: informs wehther the input tensors will have batch or sequence on the 0th dim\n",
    "        padding_idx: idx for the tensor padding        \n",
    "    \"\"\"\n",
    "    super(SurnameClassifier, self).__init__()\n",
    "    self.emb = nn.Embedding(n_embs, emb_sz, padding_idx)\n",
    "    self.rnn = ElmanRNN(inp_sz=emb_sz, hidden_sz=rnn_hidden_sz, batch_first=batch_first)\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "    self.mlp = nn.Sequential(\n",
    "      nn.Linear(rnn_hidden_sz, rnn_hidden_sz),\n",
    "      nn.ReLU(),\n",
    "      self.dropout,\n",
    "      nn.Linear(rnn_hidden_sz, n_classes)\n",
    "    )\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "  def forward(self, x_in: torch.Tensor, x_lens: torch.Tensor=None, apply_softmax: bool=False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "      The forward pass of the classifier\n",
    "      \n",
    "      Args:\n",
    "        x_in: input tensor of shape (bs, input_dim)\n",
    "        x_lens: lengths of each sequence in the batch used to find the final vector of each sequence\n",
    "        apply_softmax: flag for softmax activation, should be false when used with nn.CrossEntropy\n",
    "    \"\"\"\n",
    "#     pdb.set_trace()\n",
    "    x_emb = self.emb(x_in)\n",
    "    y_out = self.rnn(x_emb)\n",
    "    \n",
    "    if x_lens is not None:\n",
    "      y_out = column_gather(y_out, x_lens)\n",
    "    else:\n",
    "      # since batch_first is true, the output of ElmanRNN is of shape (bs, seq_sz, hidden_sz)\n",
    "      # this grabs the last hidden vector of each sequence of each batch\n",
    "      # so y_out shape goes from (bs, seq_sz, feat_sz) to (bs, feat_sz)\n",
    "      y_out = y_out[:, -1, :]\n",
    "      \n",
    "    y_out = self.dropout(y_out)\n",
    "    y_out = self.mlp(y_out)\n",
    "    \n",
    "    if apply_softmax:\n",
    "      y_out = self.softmax(y_out)\n",
    "      \n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:18.646322Z",
     "start_time": "2019-03-31T16:17:18.629676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurnameClassifier(\n",
       "  (emb): Embedding(80, 100, padding_idx=0)\n",
       "  (rnn): ElmanRNN(\n",
       "    (rnn_cell): RNNCell(100, 64)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=64, out_features=18, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SurnameClassifier(consts.char_embedding_sz, dc.vocab_size, dc.n_classes, consts.rnn_hidden_sz, \\\n",
    "                       padding_idx=dc.surname_vocab.mask_idx)\n",
    "loss_fn = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=consts.lr)\n",
    "scheduler = optim.lr_scheduler.\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:20.227354Z",
     "start_time": "2019-03-31T16:17:20.213541Z"
    }
   },
   "outputs": [],
   "source": [
    "itr = iter(dc.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:17:26.694717Z",
     "start_time": "2019-03-31T16:17:26.617619Z"
    }
   },
   "outputs": [],
   "source": [
    "x,l,y = next(itr)\n",
    "y_pred = classifier(x,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Gather Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.303863Z",
     "start_time": "2019-03-31T14:58:49.234525Z"
    }
   },
   "outputs": [],
   "source": [
    "bs=3\n",
    "hidden_sz=7\n",
    "seq_sz =5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.318921Z",
     "start_time": "2019-03-31T14:58:49.305208Z"
    }
   },
   "outputs": [],
   "source": [
    "x_lens = torch.randint(1, seq_sz+1, (bs,))\n",
    "x_lens = x_lens.long().detach().cpu().numpy()-1\n",
    "y_out = torch.randn(bs, seq_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.333806Z",
     "start_time": "2019-03-31T14:58:49.320222Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_lens.shape)\n",
    "x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.349130Z",
     "start_time": "2019-03-31T14:58:49.335043Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_out.shape)\n",
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.362427Z",
     "start_time": "2019-03-31T14:58:49.350084Z"
    }
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for batch_idx, column_idx in enumerate(x_lens):\n",
    "  out.append(y_out[batch_idx, column_idx])\n",
    "#   print(batch_idx, column_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.375812Z",
     "start_time": "2019-03-31T14:58:49.363497Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T14:58:49.390314Z",
     "start_time": "2019-03-31T14:58:49.376865Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:16:21.508199Z",
     "start_time": "2019-03-31T16:16:21.492315Z"
    }
   },
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "  \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "  def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "               rnn_hidden_size, batch_first=True, padding_idx=0):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          embedding_size (int): The size of the character embeddings\n",
    "          num_embeddings (int): The number of characters to embed\n",
    "          num_classes (int): The size of the prediction vector \n",
    "              Note: the number of nationalities\n",
    "          rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "          batch_first (bool): Informs whether the input tensors will \n",
    "              have batch or the sequence on the 0th dimension\n",
    "          padding_idx (int): The index for the tensor padding; \n",
    "              see torch.nn.Embedding\n",
    "      \"\"\"\n",
    "      super(SurnameClassifier, self).__init__()\n",
    "\n",
    "      self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                              embedding_dim=embedding_size,\n",
    "                              padding_idx=padding_idx)\n",
    "      self.rnn = ElmanRNN(embedding_size,rnn_hidden_size,batch_first)\n",
    "      self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                       out_features=rnn_hidden_size)\n",
    "      self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                        out_features=num_classes)\n",
    "\n",
    "  def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "      \"\"\"The forward pass of the classifier\n",
    "\n",
    "      Args:\n",
    "          x_in (torch.Tensor): an input data tensor. \n",
    "              x_in.shape should be (batch, input_dim)\n",
    "          x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "              They are used to find the final vector of each sequence\n",
    "          apply_softmax (bool): a flag for the softmax activation\n",
    "              should be false if used with the Cross Entropy losses\n",
    "      Returns:\n",
    "          the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "      \"\"\"\n",
    "      x_embedded = self.emb(x_in)\n",
    "      y_out = self.rnn(x_embedded)\n",
    "\n",
    "      if x_lengths is not None:\n",
    "          y_out = column_gather(y_out, x_lengths)\n",
    "      else:\n",
    "          y_out = y_out[:, -1, :]\n",
    "\n",
    "      y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
    "      y_out = self.fc2(F.dropout(y_out, 0.5))\n",
    "\n",
    "      if apply_softmax:\n",
    "          y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "      return y_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
