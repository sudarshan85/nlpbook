{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Full-Dataset-Preprocessing\" data-toc-modified-id=\"Full-Dataset-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Full Dataset Preprocessing</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Testing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ignite-Testing\" data-toc-modified-id=\"Ignite-Testing-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Ignite Testing</a></span></li><li><span><a href=\"#NLPBook-Testing\" data-toc-modified-id=\"NLPBook-Testing-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>NLPBook Testing</a></span></li><li><span><a href=\"#Predict-Rating\" data-toc-modified-id=\"Predict-Rating-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Predict Rating</a></span></li><li><span><a href=\"#Interpretablity\" data-toc-modified-id=\"Interpretablity-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Interpretablity</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Review Classifier from NLP Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp restaurant review binary classifier problem from NLP with PyTorch book. This uses the Ignite framework for training the model. The details of the problem can be found at page 57 of the book. [Here](https://nbviewer.jupyter.org/github/joosthub/PyTorchNLPBook/blob/master/chapters/chapter_3/3_5_Classifying_Yelp_Review_Sentiment.ipynb) is the notebook for training. I've made some changes in the code, refactoring the notebook code into modules.\n",
    "\n",
    "There is already a preprocessed \"lite\" dataset file which has 10\\% of the data. The code was already tested on the lite version before processing the full version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:07.303753Z",
     "start_time": "2019-03-25T16:36:07.291829Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:08.249802Z",
     "start_time": "2019-03-25T16:36:07.305079Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:08.295892Z",
     "start_time": "2019-03-25T16:36:08.251468Z"
    }
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:08.311751Z",
     "start_time": "2019-03-25T16:36:08.296999Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports from my modules\n",
    "from yelp.dataset import ProjectDataset\n",
    "from yelp.trainer import YelpTrainer\n",
    "from yelp.model import Classifier\n",
    "from yelp.args import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:08.324485Z",
     "start_time": "2019-03-25T16:36:08.312643Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('../data/yelp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:08.592666Z",
     "start_time": "2019-03-25T16:36:08.580883Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "  text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:30:29.381219Z",
     "start_time": "2019-03-25T16:30:25.880236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_reviews = pd.read_csv(path/args.raw_train_csv, header=None, names=['rating', 'review'])\n",
    "train_reviews = train_reviews[~pd.isnull(train_reviews['review'])]\n",
    "\n",
    "test_reviews = pd.read_csv(path/args.raw_test_csv, header=None, names=['rating', 'review'])\n",
    "test_reviews = test_reviews[~pd.isnull(test_reviews['review'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:30:29.407709Z",
     "start_time": "2019-03-25T16:30:29.383046Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:30:29.424426Z",
     "start_time": "2019-03-25T16:30:29.409095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:31:14.224659Z",
     "start_time": "2019-03-25T16:30:29.425498Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# splitting train by rating\n",
    "by_rating = defaultdict(list)\n",
    "for _, row in train_reviews.iterrows():\n",
    "    by_rating[row['rating']].append(row.to_dict())\n",
    "\n",
    "# create split data\n",
    "final_list = []\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "  np.random.shuffle(item_list)\n",
    "  n_total = len(item_list)\n",
    "  n_train = int(args.train_proportion * n_total)\n",
    "  n_val = int((1-args.train_proportion) * n_total)\n",
    "  \n",
    "  # give data point a split attribute\n",
    "  for item in item_list[:n_train]:\n",
    "    item['split'] = 'train'\n",
    "  \n",
    "  for item in item_list[n_train:n_train+n_val]:\n",
    "    item['split'] = 'val'\n",
    "    \n",
    "  # add to final list\n",
    "  final_list.extend(item_list)\n",
    "\n",
    "# add test split\n",
    "for _, row in test_reviews.iterrows():\n",
    "  row_dict = row.to_dict()\n",
    "  row_dict['split'] = 'test'\n",
    "  final_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:31:15.300346Z",
     "start_time": "2019-03-25T16:31:14.226642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# write split data to file\n",
    "final_reviews = pd.DataFrame(final_list)\n",
    "final_reviews.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:31:15.320463Z",
     "start_time": "2019-03-25T16:31:15.301693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_reviews['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:31:47.972247Z",
     "start_time": "2019-03-25T16:31:15.321756Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_reviews['review'] = final_reviews['review'].apply(preprocess_text)\n",
    "final_reviews['rating'] = final_reviews['rating'].apply({1: 'negative', 2: 'positive'}.get)\n",
    "final_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:31:55.164458Z",
     "start_time": "2019-03-25T16:31:47.973826Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_reviews.to_csv(path/args.full_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:20.923530Z",
     "start_time": "2019-03-25T16:36:20.909462Z"
    }
   },
   "outputs": [],
   "source": [
    "is_lite = False\n",
    "is_load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:20.942289Z",
     "start_time": "2019-03-25T16:36:20.924852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=1024, checkpointer_name='classifier', checkpointer_prefix='yelp', device='cuda:2', early_stopping_criteria=5, frequency_cutoff=25, full_dir='models/full', full_file='reviews_with_splits_full.csv', learning_rate=0.001, lite_dir='models/lite', lite_file='reviews_with_splits_lite.csv', num_epochs=100, raw_test_csv='raw_test.csv', raw_train_csv='raw_train.csv', save_dir=PosixPath('../data/yelp/models/full'), save_every=2, save_total=5, train_proportion=0.7, vectorizer_fname='vectorizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_lite:\n",
    "  scratch = path/args.lite_dir\n",
    "  review_csv = path/args.lite_file\n",
    "else:\n",
    "  scratch = path/args.full_dir\n",
    "  review_csv = path/args.full_file\n",
    "\n",
    "vectorizer_path = scratch/args.vectorizer_fname\n",
    "args.save_dir = scratch\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:24.621357Z",
     "start_time": "2019-03-25T16:36:20.943159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(review_csv)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run only once for creating vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:24.638529Z",
     "start_time": "2019-03-25T16:36:24.622914Z"
    }
   },
   "outputs": [],
   "source": [
    "if not is_load:\n",
    "  train_ds = ProjectDataset.load_data_and_create_vectorizer(df.loc[df['split'] == 'train'])\n",
    "  train_ds.save_vectorizer(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:24.776060Z",
     "start_time": "2019-03-25T16:36:24.639588Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = df.loc[df['split'] == 'train']\n",
    "train_ds = ProjectDataset.load_data_and_vectorizer(train_df, vectorizer_path)\n",
    "vectorizer = train_ds.get_vectorizer()\n",
    "train_dl = DataLoader(train_ds, args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_df = df.loc[df['split'] == 'val']\n",
    "val_ds = ProjectDataset.load_data_and_vectorizer(val_df, vectorizer_path)\n",
    "val_dl = DataLoader(val_ds, args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "data_bundle = {\n",
    "  'train_dl': train_dl,\n",
    "  'val_dl': val_dl\n",
    "}\n",
    "\n",
    "test_df = df.loc[df['split'] == 'test']\n",
    "test_ds = ProjectDataset.load_data_and_vectorizer(test_df, vectorizer_path)\n",
    "test_dl = DataLoader(test_ds, args.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:24.791919Z",
     "start_time": "2019-03-25T16:36:24.777241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392000, 168000, 38000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl.dataset), len(val_dl.dataset), len(test_dl.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is required since Ignite takes only binary values for accuray computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:57.450763Z",
     "start_time": "2019-03-25T16:36:57.392463Z"
    }
   },
   "outputs": [],
   "source": [
    "def bce_logits_wrapper(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = (torch.sigmoid(y_pred) > 0.5).long()\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:57.466497Z",
     "start_time": "2019-03-25T16:36:57.452014Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(num_features=len((vectorizer).review_vocab))\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_bundle = {\n",
    "  'module': classifier,\n",
    "  'optimizer' : optimizer,\n",
    "  'scheduler': scheduler,\n",
    "  'loss_fn': loss_func\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:36:57.479088Z",
     "start_time": "2019-03-25T16:36:57.467575Z"
    }
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True)\n",
    "metrics = {'accuracy': Accuracy(bce_logits_wrapper), 'loss': Loss(loss_func)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:34:20.282917Z",
     "start_time": "2019-03-25T16:34:20.162717Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_trainer = YelpTrainer(model_bundle, data_bundle, args, pbar, metrics)\n",
    "yelp_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:05.770601Z",
     "start_time": "2019-03-25T16:37:00.077932Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(num_features=len((vectorizer).review_vocab))\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if is_lite:\n",
    "  state_dict = torch.load(scratch/'yelp_classifier_lite.pth')\n",
    "else:\n",
    "  state_dict = torch.load(scratch/'yelp_classifier_full.pth')\n",
    "classifier.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignite Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:08.514598Z",
     "start_time": "2019-03-25T16:37:08.447030Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = create_supervised_evaluator(classifier, metrics=metrics)\n",
    "\n",
    "@evaluator.on(Events.COMPLETED)\n",
    "def log_testing_results(engine):\n",
    "  metrics = engine.state.metrics\n",
    "  print(f\"Test loss: {metrics['loss']:0.3f}\")\n",
    "  print(f\"Test accuracy: {metrics['accuracy']:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:19.454821Z",
     "start_time": "2019-03-25T16:37:08.515757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.178\n",
      "Test accuracy: 0.935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f0e61906a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.run(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLPBook Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:22.413344Z",
     "start_time": "2019-03-25T16:37:22.390844Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y):\n",
    "  y = y.type(torch.uint8)\n",
    "  y_pred = (torch.sigmoid(y_pred)>0.5)#.max(dim=1)[1]\n",
    "  n_correct = torch.eq(y_pred, y).sum().item()\n",
    "  return n_correct / len(y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:32.870771Z",
     "start_time": "2019-03-25T16:37:22.414813Z"
    }
   },
   "outputs": [],
   "source": [
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "\n",
    "classifier.eval()\n",
    "for i, batch in enumerate(test_dl):\n",
    "  x,y = batch\n",
    "  y_pred = classifier(x_in=x.float())\n",
    "  \n",
    "  loss = loss_func(y_pred, y.float())\n",
    "  loss_t = loss.item()\n",
    "  running_loss += (loss_t-running_loss)/(i+1)\n",
    "  \n",
    "  acc_t = compute_accuracy(y_pred, y)\n",
    "  running_acc += (acc_t-running_acc)/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:32.894582Z",
     "start_time": "2019-03-25T16:37:32.873625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.178\n",
      "Test acc: 93.531\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test loss: {running_loss:0.3f}\")\n",
    "print(f\"Test acc: {running_acc:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:37:35.241721Z",
     "start_time": "2019-03-25T16:37:35.226598Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):\n",
    "  \"\"\"Predict the rating of a review\n",
    "\n",
    "  Args:\n",
    "      review (str): the text of the review\n",
    "      classifier (ReviewClassifier): the trained model\n",
    "      vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
    "      decision_threshold (float): The numerical boundary which separates the rating classes\n",
    "  \"\"\"\n",
    "  review = preprocess_text(review)\n",
    "  print(review)\n",
    "\n",
    "  vectorized_review = torch.tensor(vectorizer.vectorize(review))\n",
    "  print(vectorized_review)\n",
    "  result = classifier(vectorized_review.view(1, -1))\n",
    "  print(result)\n",
    "\n",
    "  probability_value = torch.sigmoid(result).item()\n",
    "  print(probability_value)\n",
    "  index = 1\n",
    "  if probability_value < decision_threshold:\n",
    "      index = 0\n",
    "\n",
    "  return vectorizer.rating_vocab.lookup_idx(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:12.378893Z",
     "start_time": "2019-03-25T16:38:12.237399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the best movie i ve ever seen . the acting is great and the plot line is very interesting . \n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([2.7296], grad_fn=<SqueezeBackward1>)\n",
      "0.9387491345405579\n",
      "This is the best movie I've ever seen. The acting is great and the plot line is very interesting. -> positive\n"
     ]
    }
   ],
   "source": [
    "test_review = \"This is the best movie I've ever seen. The acting is great and the plot line is very interesting.\"\n",
    "\n",
    "prediction = predict_rating(test_review, classifier, vectorizer, decision_threshold=0.5)\n",
    "print(f\"{test_review} -> {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:19.724112Z",
     "start_time": "2019-03-25T16:38:19.709407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24662])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:19.741618Z",
     "start_time": "2019-03-25T16:38:19.725553Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort weights\n",
    "fc1_weights = classifier.fc1.weight.detach()[0]\n",
    "_, idxs = torch.sort(fc1_weights, dim=0, descending=True)\n",
    "idxs = idxs.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:19.760885Z",
     "start_time": "2019-03-25T16:38:19.743107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influential words in Positive Reviews:\n",
      "--------------------------------------\n",
      "exceeded\n",
      "delicious\n",
      "excellent\n",
      "pleasantly\n",
      "hooked\n",
      "amazing\n",
      "fantastic\n",
      "perfection\n",
      "awesome\n",
      "disappoint\n",
      "hesitate\n",
      "nexcellent\n",
      "perfect\n",
      "yum\n",
      "divine\n",
      "complaint\n",
      "downside\n",
      "delish\n",
      "addicting\n",
      "heaven\n",
      "====\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 20 words\n",
    "print(\"Influential words in Positive Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "for i in range(20):\n",
    "    print(vectorizer.review_vocab.lookup_idx(idxs[i]))\n",
    "    \n",
    "print(\"====\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:19.779908Z",
     "start_time": "2019-03-25T16:38:19.762301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influential words in Negative Reviews:\n",
      "--------------------------------------\n",
      "worst\n",
      "mediocre\n",
      "meh\n",
      "poisoning\n",
      "bland\n",
      "overrated\n",
      "terrible\n",
      "horrible\n",
      "slowest\n",
      "downhill\n",
      "underwhelmed\n",
      "disappointing\n",
      "tasteless\n",
      "unacceptable\n",
      "flavorless\n",
      "underwhelming\n",
      "awful\n",
      "disgusting\n",
      "disappointment\n",
      "unimpressed\n",
      "====\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 20 words\n",
    "print(\"Influential words in Negative Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "idxs.reverse()\n",
    "for i in range(20):\n",
    "    print(vectorizer.review_vocab.lookup_idx(idxs[i]))\n",
    "    \n",
    "print(\"====\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
