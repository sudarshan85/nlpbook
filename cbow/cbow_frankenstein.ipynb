{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Data-&amp;-Model\" data-toc-modified-id=\"Data-&amp;-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data &amp; Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Results</a></span></li></ul></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Testing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ignite-Testing\" data-toc-modified-id=\"Ignite-Testing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Ignite Testing</a></span></li><li><span><a href=\"#NLPBook-Testing\" data-toc-modified-id=\"NLPBook-Testing-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>NLPBook Testing</a></span></li></ul></li><li><span><a href=\"#Trained-Embeddings\" data-toc-modified-id=\"Trained-Embeddings-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Trained Embeddings</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW Training with Frankenstein Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:04.454695Z",
     "start_time": "2019-03-28T15:32:04.442241Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:05.478403Z",
     "start_time": "2019-03-28T15:32:04.456046Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:05.525041Z",
     "start_time": "2019-03-28T15:32:05.479902Z"
    }
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:05.554868Z",
     "start_time": "2019-03-28T15:32:05.526170Z"
    }
   },
   "outputs": [],
   "source": [
    "from consts import consts\n",
    "from cbow.dataset import CBOWDataset, DataContainer\n",
    "from cbow.model import CBOWClassifier, ModelContainer\n",
    "from cbow.trainer import IgniteTrainer\n",
    "consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:06.877638Z",
     "start_time": "2019-03-28T15:32:06.690441Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(consts.proc_dataset_csv)\n",
    "dc = DataContainer(df, consts.vectorizer_file, consts.batch_size, is_load=True)\n",
    "\n",
    "classifier = CBOWClassifier(dc.vocabulary_size, consts.embedding_size)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=consts.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "mc = ModelContainer(classifier, optimizer, loss_func, scheduler)\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "metrics = {'accuracy': Accuracy(), 'loss': Loss(loss_func)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T21:06:27.602191Z",
     "start_time": "2019-03-27T21:06:21.842274Z"
    }
   },
   "outputs": [],
   "source": [
    "ig = IgniteTrainer(mc, dc, consts, pbar, metrics)\n",
    "ig.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:20.039724Z",
     "start_time": "2019-03-28T15:32:20.020015Z"
    }
   },
   "outputs": [],
   "source": [
    "training_metrics = pd.read_csv(consts.metric_file)\n",
    "training_metrics = training_metrics[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:20.369256Z",
     "start_time": "2019-03-28T15:32:20.041233Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "\n",
    "training_metrics.plot(x='epoch', y=['training_loss', 'validation_loss'], kind='line',\n",
    "                      title='Training and validation loss', ax=axes[0])\n",
    "\n",
    "training_metrics.plot(x='epoch', y=['training_acc', 'validation_acc'], kind='line',\n",
    "                      title='Training and validation accuracy', ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignite Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:39.125081Z",
     "start_time": "2019-03-28T15:32:33.356086Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(consts.work_dir/'cbow_classifier.pth')\n",
    "classifier.load_state_dict(state_dict)\n",
    "evaluator = create_supervised_evaluator(classifier, metrics=metrics)\n",
    "\n",
    "@evaluator.on(Events.COMPLETED)\n",
    "def log_testing_results(engine):\n",
    "  metrics = engine.state.metrics\n",
    "  print(f\"Test loss: {metrics['loss']:0.3f}\")\n",
    "  print(f\"Test accuracy: {metrics['accuracy']:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:41.365141Z",
     "start_time": "2019-03-28T15:32:39.127035Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator.run(dc.test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLPBook Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:41.387023Z",
     "start_time": "2019-03-28T15:32:41.367119Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "  _, y_pred_indices = y_pred.max(dim=1)\n",
    "  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "  return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:43.551373Z",
     "start_time": "2019-03-28T15:32:41.388631Z"
    }
   },
   "outputs": [],
   "source": [
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "\n",
    "classifier.eval()\n",
    "for i, batch in enumerate(dc.test_dl):\n",
    "  x,y = batch\n",
    "  y_pred = classifier(x_in=x)\n",
    "  \n",
    "  loss = loss_func(y_pred, y)\n",
    "  loss_t = loss.item()\n",
    "  running_loss += (loss_t-running_loss)/(i+1)\n",
    "  \n",
    "  acc_t = compute_accuracy(y_pred, y)\n",
    "  running_acc += (acc_t-running_acc)/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:43.572516Z",
     "start_time": "2019-03-28T15:32:43.553016Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Test loss: {running_loss:0.3f}\")\n",
    "print(f\"Test acc: {running_acc:0.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:55.848762Z",
     "start_time": "2019-03-28T15:32:55.829832Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print(results):\n",
    "  for item in results:\n",
    "    print(f\"...{item[1]:0.2f} - {item[0]}\")\n",
    "    \n",
    "def get_closest(target_word, idx_word_bidict, embedings, n=5):\n",
    "  \"\"\"\n",
    "    Get the n closest words to the target word\n",
    "  \"\"\"\n",
    "  # calculate distances to all other words\n",
    "  word_embedding = embeddings[idx_word_bidict.inverse[target_word.lower()]]\n",
    "  distances = []\n",
    "  \n",
    "  for idx, word in idx_word_bidict.items():\n",
    "    if word == '<MASK>' or word == target_word:\n",
    "      continue\n",
    "    distances.append((word, torch.dist(word_embedding, embeddings[idx])))\n",
    "    \n",
    "  results = sorted(distances, key=lambda x: x[1])[1:n+2]\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T15:32:57.139415Z",
     "start_time": "2019-03-28T15:32:55.850270Z"
    }
   },
   "outputs": [],
   "source": [
    "target_words = ['frankenstein', 'monster', 'hello', 'science', 'sickness', 'lonely', 'happy']\n",
    "embeddings = classifier.embedding.weight.data\n",
    "idx_word_bidict = dc.vocabulary.idx_token_bidict\n",
    "\n",
    "for target_word in target_words:\n",
    "  print(f\"========={target_word}============\")\n",
    "  try:\n",
    "    idx_word_bidict.inverse[target_word]\n",
    "  except:\n",
    "    print(f\"Word {target_word} not in vocabulary\")\n",
    "    continue\n",
    "  pretty_print(get_closest(target_word, idx_word_bidict, embeddings, n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T14:28:36.282237Z",
     "start_time": "2019-03-28T14:28:33.997980Z"
    }
   },
   "outputs": [],
   "source": [
    "word = input(\"Enter a word: \")\n",
    "embeddings = classifier.embedding.weight.data\n",
    "idx_word_bidict = dc.vocabulary.idx_token_bidict\n",
    "pretty_print(get_closest(word, idx_word_bidict, embeddings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
