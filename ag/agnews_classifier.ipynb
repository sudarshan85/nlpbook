{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Data-&amp;-Model\" data-toc-modified-id=\"Data-&amp;-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data &amp; Model</a></span></li><li><span><a href=\"#Going-through-the-model\" data-toc-modified-id=\"Going-through-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Going through the model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG News Classifier with ConvNet\n",
    "Classifier to classify news titles into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:50.169534Z",
     "start_time": "2019-03-29T12:25:50.157622Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:51.207173Z",
     "start_time": "2019-03-29T12:25:50.170749Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:51.239364Z",
     "start_time": "2019-03-29T12:25:51.208806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=256, checkpointer_name='classifier', checkpointer_prefix='cbow', cw_file=PosixPath('../data/ag_news/work_dir/class_weights.pth'), device='cuda:3', dropout_p=0.1, early_stopping_criteria=5, embedding_size=100, glove_path=PosixPath('../pretrained_path/glove6B/glove.6B.100d.txt'), hidden_dim=100, learning_rate=0.001, metric_file=PosixPath('../data/ag_news/work_dir/metrics.csv'), model_dir=PosixPath('../data/ag_news/work_dir/models'), n_channels=100, num_epochs=100, path=PosixPath('../data/ag_news'), proc_dataset_csv=PosixPath('../data/ag_news/news_with_splits.csv'), save_every=2, save_total=5, use_glove=False, vectorizer_file=PosixPath('../data/ag_news/work_dir/vectorizer.json'), work_dir=PosixPath('../data/ag_news/work_dir'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from consts import consts\n",
    "from ag.data import NewsDataset, DataContainer\n",
    "consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:51.375543Z",
     "start_time": "2019-03-29T12:25:51.240478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>train</td>\n",
       "      <td>Jobs, tax cuts key issues for Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business</td>\n",
       "      <td>train</td>\n",
       "      <td>Jarden Buying Mr. Coffee #39;s Maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>train</td>\n",
       "      <td>Retail sales show festive fervour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>train</td>\n",
       "      <td>Intervoice's Customers Come Calling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>train</td>\n",
       "      <td>Boeing Expects Air Force Contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  split                                 title\n",
       "0  Business  train    Jobs, tax cuts key issues for Bush\n",
       "1  Business  train  Jarden Buying Mr. Coffee #39;s Maker\n",
       "2  Business  train     Retail sales show festive fervour\n",
       "3  Business  train   Intervoice's Customers Come Calling\n",
       "4  Business  train     Boeing Expects Air Force Contract"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(consts.proc_dataset_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:51.475537Z",
     "start_time": "2019-03-29T12:25:51.376658Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = DataContainer(df, NewsDataset, consts.vectorizer_file, consts.batch_size, is_load=True)\n",
    "\n",
    "try:\n",
    "  class_weights = torch.load(consts.cw_file)\n",
    "except FileNotFoundError:\n",
    "  cat_vocab = dc.cat_vocab\n",
    "  class_counts = df['category'].value_counts().to_dict()\n",
    "  sorted_counts = sorted(class_counts.items(), key=lambda x: cat_vocab.lookup_token(x[0]))\n",
    "  freq = [count for _, count in sorted_counts]\n",
    "  class_weights = 1.0/torch.tensor(freq, dtype=torch.float32)\n",
    "  torch.save(class_weights, consts.cw_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T01:50:14.583484Z",
     "start_time": "2019-03-29T01:50:14.564609Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "  def __init__(self, emb_sz, vocab_size, n_channels, hidden_dim, n_classes, dropout_p,\n",
    "               pretrained=None, freeze_pretrained=False, padding_idx=0):\n",
    "    super(NewsClassifier, self).__init__()\n",
    "    \n",
    "    if pretrained:\n",
    "      pretrained_emb = torch.from_numpy(pretrained).float()\n",
    "      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx, _weight=pretrained_emb)\n",
    "      if freeze_pretrained:\n",
    "        self.emb.weight.requires_grad = False\n",
    "    else:\n",
    "      self.emb = nn.Embedding(vocab_size, emb_sz, padding_idx)\n",
    "      \n",
    "    self.convnet = nn.Sequential(\n",
    "      nn.Conv1d(in_channels=emb_sz, out_channels=n_channels, kernel_size=3),\n",
    "      nn.ELU(),\n",
    "      nn.Conv1d(in_channels=n_channels, out_channels=n_channels, kernel_size=3, stride=2),\n",
    "      nn.ELU(),\n",
    "      nn.Conv1d(in_channels=n_channels, out_channels=n_channels, kernel_size=3, stride=2),\n",
    "      nn.ELU(),\n",
    "      nn.Conv1d(in_channels=n_channels, out_channels=n_channels, kernel_size=3),\n",
    "      nn.ELU()\n",
    "    )\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=dropout_p)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc1 = nn.Linear(in_features=n_channels, out_features=hidden_dim)\n",
    "    self.fc2 = nn.Linear(in_features=hidden_dim, out_features=n_classes)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "  def forward(self, x_in, apply_softmax=False):\n",
    "    # embed and permute so features are channels\n",
    "    # conv1d (batch, channels, input)\n",
    "    pdb.set_trace()\n",
    "    x_emb = self.emb(x_in).permute(0,2,1)\n",
    "    features = self.convnet(x_emb)\n",
    "    \n",
    "    # average and remove extra dimension\n",
    "    remaining_size = features.size(dim=2)\n",
    "    features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
    "    features = self.dropout(features)\n",
    "    \n",
    "    # mlp classifier\n",
    "    hidden_vector = self.fc1(features)\n",
    "    hidden_vector = self.dropout(hidden_vector)\n",
    "    hidden_vector = self.relu(hidden_vector)\n",
    "    prediction_vector = self.fc2(hidden_vector)\n",
    "    \n",
    "    if apply_softmax:\n",
    "      prediction_vector = self.softmax(prediction_vector)\n",
    "      \n",
    "    return prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T01:50:14.603731Z",
     "start_time": "2019-03-29T01:50:14.584487Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = NewsClassifier(consts.embedding_size, dc.vocab_size, consts.n_channels, consts.hidden_dim,\n",
    "                            dc.n_cats, consts.dropout_p)\n",
    "loss_fn = nn.CrossEntropyLoss(class_weights)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T01:50:14.721773Z",
     "start_time": "2019-03-29T01:50:14.605035Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = next(itr)\n",
    "y_pred = classifier(x)\n",
    "loss_fn(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:54.906329Z",
     "start_time": "2019-03-29T12:25:54.885745Z"
    }
   },
   "outputs": [],
   "source": [
    "emb = nn.Embedding(dc.vocab_size, consts.embedding_size)\n",
    "conv1s = nn.Sequential(\n",
    "      nn.Conv1d(in_channels=consts.embedding_size, out_channels=consts.n_channels, kernel_size=3, padding=1),\n",
    "      nn.ELU())\n",
    "conv2s = nn.Sequential(nn.Conv1d(in_channels=consts.n_channels, out_channels=consts.n_channels,\n",
    "         kernel_size=3, stride=2), nn.ELU())\n",
    "dropout = nn.Dropout(p=consts.dropout_p)\n",
    "relu = nn.ReLU()\n",
    "fc1 = nn.Linear(in_features=consts.n_channels, out_features=consts.hidden_dim)\n",
    "fc2 = nn.Linear(in_features=consts.hidden_dim, out_features=dc.n_cats)\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:57.834232Z",
     "start_time": "2019-03-29T12:25:57.820701Z"
    }
   },
   "outputs": [],
   "source": [
    "itr = iter(dc.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:25:57.878396Z",
     "start_time": "2019-03-29T12:25:57.835403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 20]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "x,y = next(itr)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:01.009419Z",
     "start_time": "2019-03-29T12:26:00.990757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(3566, 100)\n",
      "torch.Size([256, 20, 100])\n",
      "torch.Size([256, 100, 20])\n"
     ]
    }
   ],
   "source": [
    "print(emb)\n",
    "t = emb(x)\n",
    "print(t.shape)\n",
    "t = t.permute(0,2,1)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:12.594622Z",
     "start_time": "2019-03-29T12:26:12.565759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (1): ELU(alpha=1.0)\n",
      ")\n",
      "torch.Size([256, 100, 20])\n"
     ]
    }
   ],
   "source": [
    "print(conv1s)\n",
    "t = conv1s(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:20.352702Z",
     "start_time": "2019-03-29T12:26:20.331869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
      "  (1): ELU(alpha=1.0)\n",
      ")\n",
      "torch.Size([256, 100, 9])\n"
     ]
    }
   ],
   "source": [
    "print(conv2s)\n",
    "t = conv2s(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:34.388687Z",
     "start_time": "2019-03-29T12:26:34.370801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
      "  (1): ELU(alpha=1.0)\n",
      ")\n",
      "torch.Size([256, 100, 4])\n"
     ]
    }
   ],
   "source": [
    "print(conv2s)\n",
    "t = conv2s(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:35.922980Z",
     "start_time": "2019-03-29T12:26:35.904177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (1): ELU(alpha=1.0)\n",
      ")\n",
      "torch.Size([256, 100, 4])\n"
     ]
    }
   ],
   "source": [
    "print(conv1s)\n",
    "t = conv1s(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:38.303043Z",
     "start_time": "2019-03-29T12:26:38.284968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.avg_pool1d(t, 3)\n",
    "print(p.shape)\n",
    "torch.all(p==t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:40.422747Z",
     "start_time": "2019-03-29T12:26:40.406037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100])\n"
     ]
    }
   ],
   "source": [
    "p = p.squeeze(dim=2)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:41.832754Z",
     "start_time": "2019-03-29T12:26:41.813921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "torch.Size([256, 100])\n"
     ]
    }
   ],
   "source": [
    "print(fc1)\n",
    "p = fc1(p)\n",
    "p = dropout(p)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:26:42.969845Z",
     "start_time": "2019-03-29T12:26:42.957360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=4, bias=True)\n",
      "torch.Size([256, 4])\n"
     ]
    }
   ],
   "source": [
    "print(fc2)\n",
    "p = fc2(p)\n",
    "print(p.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
