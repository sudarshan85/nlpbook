{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Inits\" data-toc-modified-id=\"Imports-&amp;-Inits-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Inits</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Model</a></span></li></ul></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Testing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ignite-Testing\" data-toc-modified-id=\"Ignite-Testing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Ignite Testing</a></span></li><li><span><a href=\"#NLPBook-Testing\" data-toc-modified-id=\"NLPBook-Testing-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>NLPBook Testing</a></span></li></ul></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inference</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predict-Rating\" data-toc-modified-id=\"Predict-Rating-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Predict Rating</a></span></li></ul></li><li><span><a href=\"#Interpretablity\" data-toc-modified-id=\"Interpretablity-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Interpretablity</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Review Classifier from NLP Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:11.307728Z",
     "start_time": "2019-03-23T17:20:11.296904Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:11.813951Z",
     "start_time": "2019-03-23T17:20:11.309094Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:11.856273Z",
     "start_time": "2019-03-23T17:20:11.815774Z"
    }
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:11.871706Z",
     "start_time": "2019-03-23T17:20:11.857491Z"
    }
   },
   "outputs": [],
   "source": [
    "from yelp.dataset import ProjectDataset\n",
    "from yelp.trainer import YelpTrainer\n",
    "from yelp.model import Classifier\n",
    "from yelp.args import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.227019Z",
     "start_time": "2019-03-23T17:20:11.872632Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('./data/yelp')\n",
    "review_csv = path/args.sample_file\n",
    "scratch = path/args.workdir_name\n",
    "vectorizer_path = scratch/args.vectorizer_fname\n",
    "args.save_dir = scratch\n",
    "\n",
    "df = pd.read_csv(review_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.245849Z",
     "start_time": "2019-03-23T17:20:12.228259Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args.num_epochs=2\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run only once for creating vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.259378Z",
     "start_time": "2019-03-23T17:20:12.246909Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_ds = ProjectDataset.load_data_and_create_vectorizer(df.loc[df['split'] == 'train'])\n",
    "# train_ds.save_vectorizer(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.291825Z",
     "start_time": "2019-03-23T17:20:12.260780Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = df.loc[df['split'] == 'train']\n",
    "train_ds = ProjectDataset.load_data_and_vectorizer(train_df, vectorizer_path)\n",
    "vectorizer = train_ds.get_vectorizer()\n",
    "train_dl = DataLoader(train_ds, args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_df = df.loc[df['split'] == 'val']\n",
    "val_ds = ProjectDataset.load_data_and_vectorizer(val_df, vectorizer_path)\n",
    "val_dl = DataLoader(val_ds, args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_df = df.loc[df['split'] == 'test']\n",
    "test_ds = ProjectDataset.load_data_and_vectorizer(test_df, vectorizer_path)\n",
    "test_dl = DataLoader(test_ds, args.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.305075Z",
     "start_time": "2019-03-23T17:20:12.292927Z"
    }
   },
   "outputs": [],
   "source": [
    "def bce_logits_wrapper(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = (torch.sigmoid(y_pred) > 0.5).long()\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:20:12.319663Z",
     "start_time": "2019-03-23T17:20:12.306009Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(num_features=len((vectorizer).review_vocab))\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "metrics = {'accuracy': Accuracy(bce_logits_wrapper), 'loss': Loss(loss_func)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T17:30:42.070385Z",
     "start_time": "2019-03-23T17:30:12.444382Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_trainer = YelpTrainer(classifier, optimizer, loss_func, train_dl, val_dl, args, pbar, metrics)\n",
    "yelp_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignite Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:07.191799Z",
     "start_time": "2019-03-23T16:39:02.756430Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(scratch/'yelp_classifier_lite')\n",
    "classifier.load_state_dict(state_dict)\n",
    "\n",
    "evaluator = create_supervised_evaluator(classifier, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:07.211356Z",
     "start_time": "2019-03-23T16:39:07.193368Z"
    }
   },
   "outputs": [],
   "source": [
    "@evaluator.on(Events.COMPLETED)\n",
    "def log_testing_results(engine):\n",
    "  metrics = engine.state.metrics\n",
    "  print(f\"Test loss: {metrics['loss']:0.3f}\")\n",
    "  print(f\"Test accuracy: {metrics['accuracy']:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:09.110926Z",
     "start_time": "2019-03-23T16:39:07.212601Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator.run(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLPBook Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:09.132172Z",
     "start_time": "2019-03-23T16:39:09.112622Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y):\n",
    "  y = y.type(torch.uint8)\n",
    "  y_pred = (torch.sigmoid(y_pred)>0.5)#.max(dim=1)[1]\n",
    "  n_correct = torch.eq(y_pred, y).sum().item()\n",
    "  return n_correct / len(y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:09.151818Z",
     "start_time": "2019-03-23T16:39:09.133572Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(scratch/'yelp_classifier_54.pth')\n",
    "classifier.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:09.169691Z",
     "start_time": "2019-03-23T16:39:09.153057Z"
    }
   },
   "outputs": [],
   "source": [
    "running_loss = 0.\n",
    "running_acc = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:09.189784Z",
     "start_time": "2019-03-23T16:39:09.171008Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:10.936167Z",
     "start_time": "2019-03-23T16:39:09.191521Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(test_dl):\n",
    "  x,y = batch\n",
    "  y_pred = classifier(x_in=x.float())\n",
    "  \n",
    "  loss = loss_func(y_pred, y.float())\n",
    "  loss_t = loss.item()\n",
    "  running_loss += (loss_t-running_loss)/(i+1)\n",
    "  \n",
    "  acc_t = compute_accuracy(y_pred, y)\n",
    "  running_acc += (acc_t-running_acc)/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:39:10.957239Z",
     "start_time": "2019-03-23T16:39:10.937929Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Test loss: {running_loss:0.3f}\")\n",
    "print(f\"Test acc: {running_acc:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:40:15.973070Z",
     "start_time": "2019-03-23T16:40:15.833312Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:41:09.759288Z",
     "start_time": "2019-03-23T16:41:09.741864Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "  text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:44:54.804933Z",
     "start_time": "2019-03-23T16:44:54.787226Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):\n",
    "  \"\"\"Predict the rating of a review\n",
    "\n",
    "  Args:\n",
    "      review (str): the text of the review\n",
    "      classifier (ReviewClassifier): the trained model\n",
    "      vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
    "      decision_threshold (float): The numerical boundary which separates the rating classes\n",
    "  \"\"\"\n",
    "  review = preprocess_text(review)\n",
    "  print(review)\n",
    "\n",
    "  vectorized_review = torch.tensor(vectorizer.vectorize(review))\n",
    "  print(vectorized_review)\n",
    "  result = classifier(vectorized_review.view(1, -1))\n",
    "  print(result)\n",
    "\n",
    "  probability_value = torch.sigmoid(result).item()\n",
    "  print(probability_value)\n",
    "  index = 1\n",
    "  if probability_value < decision_threshold:\n",
    "      index = 0\n",
    "\n",
    "  return vectorizer.rating_vocab.lookup_idx(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:46:33.070785Z",
     "start_time": "2019-03-23T16:46:33.055537Z"
    }
   },
   "outputs": [],
   "source": [
    "test_review = \"While the begining of this book is great, the ending sucks\"\n",
    "\n",
    "classifier = classifier.cpu()\n",
    "prediction = predict_rating(test_review, classifier, vectorizer, decision_threshold=0.5)\n",
    "print(f\"{test_review} -> {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:47:49.129873Z",
     "start_time": "2019-03-23T16:47:49.116209Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:49:07.777506Z",
     "start_time": "2019-03-23T16:49:07.763773Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort weights\n",
    "fc1_weights = classifier.fc1.weight.detach()[0]\n",
    "_, idxs = torch.sort(fc1_weights, dim=0, descending=True)\n",
    "idxs = idxs.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:51:11.816362Z",
     "start_time": "2019-03-23T16:51:11.797786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top 20 words\n",
    "print(\"Influential words in Positive Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "for i in range(20):\n",
    "    print(vectorizer.review_vocab.lookup_idx(idxs[i]))\n",
    "    \n",
    "print(\"====\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T16:51:35.779629Z",
     "start_time": "2019-03-23T16:51:35.636156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top 20 words\n",
    "print(\"Influential words in Negative Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "idxs.reverse()\n",
    "for i in range(20):\n",
    "    print(vectorizer.review_vocab.lookup_idx(idxs[i]))\n",
    "    \n",
    "print(\"====\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
