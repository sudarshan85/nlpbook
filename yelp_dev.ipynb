{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:52.343945Z",
     "start_time": "2019-03-22T15:30:52.332374Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.293582Z",
     "start_time": "2019-03-22T15:30:52.345172Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.340022Z",
     "start_time": "2019-03-22T15:30:53.295444Z"
    }
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.354933Z",
     "start_time": "2019-03-22T15:30:53.341178Z"
    }
   },
   "outputs": [],
   "source": [
    "from yelp.dataset import ProjectDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.707197Z",
     "start_time": "2019-03-22T15:30:53.355918Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('./data/yelp')\n",
    "review_csv = path/'reviews_with_splits_lite.csv'\n",
    "scratch = path/'scratch'\n",
    "vectorizer_path = scratch/'vectorizer.json'\n",
    "\n",
    "df = pd.read_csv(review_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.722355Z",
     "start_time": "2019-03-22T15:30:53.708414Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_ds = ProjectDataset.load_data_and_create_vectorizer(df.loc[df['split'] == 'train'])\n",
    "# train_ds.save_vectorizer(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:53.751503Z",
     "start_time": "2019-03-22T15:30:53.723295Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = df.loc[df['split'] == 'train']\n",
    "train_ds = ProjectDataset.load_data_and_vectorizer(train_df, vectorizer_path)\n",
    "vectorizer = train_ds.get_vectorizer()\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "val_df = df.loc[df['split'] == 'val']\n",
    "val_ds = ProjectDataset.load_data_and_vectorizer(val_df, vectorizer_path)\n",
    "val_dl = DataLoader(val_ds, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:55:36.805878Z",
     "start_time": "2019-03-22T14:55:36.792692Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_all_seed(seed, cuda):\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:55:36.831859Z",
     "start_time": "2019-03-22T14:55:36.820092Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = ProjectDataset.load_data_and_create_vectorizer(review_csv)\n",
    "# dataset.save_vectorizer(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:36.228735Z",
     "start_time": "2019-03-22T14:56:36.089229Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True):\n",
    "  \"\"\"\n",
    "  A generator function which wraps the PyTorch DataLoader. It will \n",
    "    ensure each tensor is on the write device location.\n",
    "  \"\"\"\n",
    "  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "  for data_dict in dataloader:\n",
    "      yield (data_dict['x_data'].float(), data_dict['y_target'].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:37.534408Z",
     "start_time": "2019-03-22T14:56:37.167162Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ProjectDataset.load_data_and_vectorizer(review_csv, vectorizer_path)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "dataset.set_split('train')\n",
    "# train_dl = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "# dataset.set_split('val')\n",
    "# val_dl = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:37.886201Z",
     "start_time": "2019-03-22T14:56:37.872169Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = generate_batches(dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:39.974488Z",
     "start_time": "2019-03-22T14:56:39.960490Z"
    }
   },
   "outputs": [],
   "source": [
    "itr = iter(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:40.004406Z",
     "start_time": "2019-03-22T14:56:39.975816Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:56:40.024934Z",
     "start_time": "2019-03-22T14:56:40.005625Z"
    }
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:30:58.019862Z",
     "start_time": "2019-03-22T15:30:58.003441Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "  def __init__(self, num_features):\n",
    "    super(ReviewClassifier, self).__init__()\n",
    "    self.fc1 = nn.Linear(in_features=num_features, out_features=1)\n",
    "    \n",
    "  def forward(self, x_in, apply_sigmoid=False):\n",
    "    y_out = self.fc1(x_in).squeeze(1)\n",
    "    if apply_sigmoid:\n",
    "      y_out = torch.sigmoid(y_out)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:31:09.450005Z",
     "start_time": "2019-03-22T15:31:09.333082Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = ReviewClassifier(num_features=len((vectorizer).review_vocab))\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:31:12.411161Z",
     "start_time": "2019-03-22T15:31:12.397356Z"
    }
   },
   "outputs": [],
   "source": [
    "def bce_logits_wrapper(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = (torch.sigmoid(y_pred) > 0.5).long()\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:31:18.034834Z",
     "start_time": "2019-03-22T15:31:12.412320Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(classifier, optimizer, loss_func, device='cuda:3')\n",
    "evaluator = create_supervised_evaluator(classifier, metrics=\\\n",
    "                                        {'accuracy':Accuracy(bce_logits_wrapper),\\\n",
    "                                         'bce': Loss(loss_func)}, device='cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:31:18.054713Z",
     "start_time": "2019-03-22T15:31:18.037396Z"
    }
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, output_transform=lambda x: {'loss': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:31:18.070425Z",
     "start_time": "2019-03-22T15:31:18.055782Z"
    }
   },
   "outputs": [],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_training_results(engine):\n",
    "#   evaluator.run(batches)\n",
    "#   metrics = evaluator.state.metrics\n",
    "#   pbar.log_message(f\"Training Results - Epoch: {engine.state.epoch}\\\n",
    "#                     Avg accuracy: {metrics['accuracy']:0.2f}\\\n",
    "#                     Avg loss: {metrics['bce']:0.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "  evaluator.run(train_dl)\n",
    "  metrics = evaluator.state.metrics\n",
    "  pbar.log_message(f\"Training Results - Epoch: {engine.state.epoch}\\\n",
    "                    Avg accuracy: {metrics['accuracy']:0.2f}\\\n",
    "                    Avg loss: {metrics['bce']:0.2f}\")\n",
    "                   \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "  evaluator.run(val_dl)\n",
    "  metrics = evaluator.state.metrics\n",
    "  pbar.log_message(f\"Validation Results - Epoch: {engine.state.epoch}\\\n",
    "                    Avg accuracy: {metrics['accuracy']:0.2f}\\\n",
    "                    Avg loss: {metrics['bce']:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:32:06.844046Z",
     "start_time": "2019-03-22T15:31:37.033101Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.run(train_dl, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T23:21:37.974916Z",
     "start_time": "2019-03-21T23:21:37.962283Z"
    }
   },
   "outputs": [],
   "source": [
    "itr = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T23:21:38.012608Z",
     "start_time": "2019-03-21T23:21:37.976056Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = next(itr)\n",
    "y_pred = classifier(x)\n",
    "loss = loss_func(y_pred, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
